# DeepECG-SL (WCR) - Vollständige Konfiguration
# Enthält alle Parameter: Daten, Preprocessing, Augmentation, Training, Modell
# Self-supervised pretrained model with Transfer Learning
# Based on: https://github.com/HeartWise-AI/DeepECG_Docker
# WCR = Wav2Vec2 with Contrastive Multi-view Coding (CMSC)

# =============================================================================
# GENERAL SETTINGS
# =============================================================================

seed: 42

device:
  device: null
  deterministic: false

# =============================================================================
# DATA SETTINGS
# =============================================================================

data:
  data_dir: "data/icu_ecgs_24h/P1"
  sampling_rate: 500.0
  window_seconds: 10.0
  num_leads: 12
  
  los_task: "regression"
  split_strategy: "temporal_stratified"
  
  preprocessing:
    target_sampling_rate: 500.0
    window_seconds: 10.0
    filter_type: "bandpass"
    filter_lowcut: 0.5
    filter_highcut: 50.0
    filter_order: 4
    normalize: "zscore"
  
  augmentation:
    enabled: true
    gaussian_noise: true
    noise_std: 0.03
    amplitude_scaling: true
    scale_min: 0.85
    scale_max: 1.15
  
  demographic_features:
    enabled: false
    records_csv_path: "data/labeling/labels_csv/records_w_diag_icd10.csv"
  
  diagnosis_features:
    enabled: false
  
  icu_unit_features:
    enabled: true
    encoding: "onehot"
    icu_unit_list:
      - "Medical Intensive Care Unit (MICU)"
      - "Medical/Surgical Intensive Care Unit (MICU/SICU)"
      - "Cardiac Vascular Intensive Care Unit (CVICU)"
      - "Surgical Intensive Care Unit (SICU)"
      - "Coronary Care Unit (CCU)"
      - "Trauma SICU (TSICU)"
      - "Neuro Intermediate"
      - "Neuro Surgical Intensive Care Unit (Neuro SICU)"
      - "Neuro Stepdown"
      - "Surgery/Vascular/Intermediate"
    unknown_strategy: "other"
    missing_strategy: "most_common"

# =============================================================================
# MODEL ARCHITECTURE
# =============================================================================

model:
  type: "DeepECG_SL"
  num_classes: 8  # Will be overridden by los_binning config (exact_days with max_days=7)
  
  # WCR Encoder Configuration
  # Architecture from fairseq-signals:
  # - 4 Conv layers [(256, 2, 2)] for feature extraction
  # - 12 Transformer encoder layers with embed_dim=768
  wcr:
    model_name: "wcr_77_classes"
    huggingface_repo: "heartwise/wcr_77_classes"
    base_ssl_path: "base_ssl.pt"
    d_model: 768                    # Transformer encoder embed dimension (from checkpoint)
    freeze_backbone: false          # Full fine-tuning: gesamtes Modell + Demographics
    
  # Input Adapter Configuration
  # WCR expects (B, 12, 2500) input format
  # Our data is (B, 12, 5000) @ 500Hz, need to downsample to 2500
  input_adapter:
    type: "conv1d"                  # conv1d, linear, or pooling
    in_length: 5000
    out_length: 2500
    kernel_size: 3
    stride: 2
    
  # Pretrained weights (automatic download)
  pretrained:
    enabled: true
    cache_dir: "data/pretrained_weights/deepecg_sl"
    # API Key from environment variable HUGGINGFACE_API_KEY
    
  # Feature dimensions
  feature_dim: 768                  # Output from WCR encoder (encoder_embed_dim)
  shared_dim: 256                   # Shared layer dimension

# =============================================================================
# TRAINING HYPERPARAMETERS
# =============================================================================

training:
  batch_size: 32
  num_epochs: 50
  num_workers: 4
  pin_memory: true
  
  optimizer:
    type: "Adam"
    lr: 5e-4
    weight_decay: 1e-2
    betas: [0.9, 0.98]
  
  gradient_clip_norm: 1.0
  dropout_rate: 0.1
  
  scheduler:
    type: "ReduceLROnPlateau"
    factor: 0.5
    patience: 8
    min_lr: 1e-6
  
  loss:
    type: "mse"

# =============================================================================
# VALIDATION & TEST SETTINGS
# =============================================================================

validation:
  val_split: 0.1
  val_frequency: 1

test_split: 0.1

# =============================================================================
# EARLY STOPPING
# =============================================================================

early_stopping:
  enabled: true
  patience: 15
  monitor: "val_loss"
  mode: "min"

# =============================================================================
# CHECKPOINTING & LOGGING
# =============================================================================

checkpoint:
  save_dir: "outputs/checkpoints"
  save_frequency: 1
  save_best: true
  metric: "val_loss"

logging:
  log_dir: "outputs/logs"
  use_tensorboard: true
  log_frequency: 10

# =============================================================================
# EVALUATION METRICS
# =============================================================================

evaluation:
  metrics:
    - "mae"
    - "rmse"
    - "r2"
    - "median_ae"
    - "accuracy"
    - "auc_roc"

# =============================================================================
# MULTI-TASK LEARNING
# =============================================================================

multi_task:
  enabled: true
  admissions_path: "data/labeling/labels_csv/admissions.csv"
  los_loss_weight: 1.0
  mortality_loss_weight: 1.0
  mortality_use_weighted_loss: false
  mortality_pos_weight: null
