# HuBERT-ECG - Vollständige Konfiguration
# Enthält alle Parameter: Daten, Preprocessing, Augmentation, Training, Modell
# Self-supervised pretrained model with Transfer Learning

# =============================================================================
# GENERAL SETTINGS
# =============================================================================

seed: 42

device:
  device: null
  deterministic: false

# =============================================================================
# DATA SETTINGS
# =============================================================================

data:
  data_dir: "data/icu_ecgs_24h/P1"
  sampling_rate: 500.0
  window_seconds: 10.0
  num_leads: 12
  
  los_task: "regression"
  split_strategy: "temporal_stratified"
  
  preprocessing:
    target_sampling_rate: 500.0
    window_seconds: 10.0
    filter_type: "bandpass"
    filter_lowcut: 0.5
    filter_highcut: 50.0
    filter_order: 4
    normalize: "zscore"
  
  augmentation:
    enabled: true
    gaussian_noise: true
    noise_std: 0.03
    amplitude_scaling: true
    scale_min: 0.85
    scale_max: 1.15
  
  # Variable Late Fusion Features
  demographic_features:
    enabled: false  # Disabled for head-only baseline (H1)
  
  diagnosis_features:
    enabled: false

# =============================================================================
# MODEL ARCHITECTURE
# =============================================================================

model:
  type: "HuBERT_ECG"
  num_classes: 8  # Will be overridden by los_binning config (exact_days with max_days=7)
  
  # HuBERT Encoder Configuration
  hubert:
    checkpoint_path: "model.safetensors"  # Relative to cache_dir, or absolute path
    config_path: "config.json"  # Optional, relative to cache_dir
    hidden_size: 768  # HuBERT hidden dimension
    freeze_backbone: true  # Initial freeze for transfer learning (Phase 1)
    # Preprocessing configuration:
    # - apply_preprocessing: false (default) - Use for P1 dataset which is already preprocessed:
    #   * Bandpass: Butterworth (0.5-50 Hz, 4th order, filtfilt)
    #   * Resampling: 500 Hz
    #   * Segmentation: 10s = 5000 samples
    #   * Normalization: Z-score per lead (mean=0, std=1)
    # - apply_preprocessing: true - Apply HuBERT-specific preprocessing (for raw data only):
    #   * Bandpass: FIR (0.05-47 Hz) - DIFFERENT from P1 preprocessing!
    #   * Normalization: Min-Max scaling [-1, 1] - DIFFERENT from P1 preprocessing!
    #   WARNING: Do not apply both preprocessing methods - they are incompatible!
    apply_preprocessing: false  # false = use P1 preprocessed data (recommended)
    
  # NO input_adapter Config!
  # HuBERT has built-in Feature Extractor (5 Conv Layers with downsampling)
  # Input: (B, 12, 5000) @ 500Hz → Feature Extractor → (B, seq_len, 768)
  
  # Pretrained weights
  pretrained:
    enabled: true
    cache_dir: "data/pretrained_weights/Hubert_ECG/base"
    
  # Feature dimensions
  feature_dim: 768  # Output from HuBERT encoder
  shared_dim: 128  # Shared layer dimension

# =============================================================================
# TRAINING HYPERPARAMETERS
# =============================================================================

training:
  batch_size: 32  # Reduced from 64 to avoid OOM (HuBERT encoder activations ~78 GB)
  num_epochs: 50
  num_workers: 4
  pin_memory: true
  
  optimizer:
    type: "Adam"
    lr: 5e-4
    weight_decay: 1e-4
    betas: [0.9, 0.999]
  
  gradient_clip_norm: 1.0
  dropout_rate: 0.1  # classifier_dropout_prob from original HuBERT-ECG paper (default: 0.1)
  
  scheduler:
    type: "ReduceLROnPlateau"
    factor: 0.1
    patience: 5
    min_lr: 1e-6
  
  loss:
    type: "mse"

# =============================================================================
# VALIDATION & TEST SETTINGS
# =============================================================================

validation:
  val_split: 0.1
  val_frequency: 1

test_split: 0.1

# =============================================================================
# EARLY STOPPING
# =============================================================================

early_stopping:
  enabled: true
  patience: 7
  monitor: "val_loss"
  mode: "min"

# =============================================================================
# CHECKPOINTING & LOGGING
# =============================================================================

checkpoint:
  save_dir: "outputs/checkpoints"
  save_frequency: 1
  save_best: true
  metric: "val_loss"

logging:
  log_dir: "outputs/logs"
  use_tensorboard: true
  log_frequency: 10

# =============================================================================
# EVALUATION METRICS
# =============================================================================

evaluation:
  metrics:
    - "mae"
    - "rmse"
    - "r2"
    - "median_ae"
    - "accuracy"
    - "auc_roc"

# =============================================================================
# MULTI-TASK LEARNING
# =============================================================================

multi_task:
  enabled: true
  admissions_path: "data/labeling/labels_csv/admissions.csv"
  los_loss_weight: 1.0
  mortality_loss_weight: 1.0
  los_use_weighted_loss: false
  mortality_use_weighted_loss: false
  mortality_pos_weight: null
