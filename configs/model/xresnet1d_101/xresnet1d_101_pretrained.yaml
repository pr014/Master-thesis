# FastAI xResNet1D-101 (Pretrained) - Vollständige Konfiguration
# Enthält alle Parameter: Daten, Preprocessing, Augmentation, Training, Modell
# Pretrained on PTB-XL dataset

# =============================================================================
# GENERAL SETTINGS
# =============================================================================

seed: 42

device:
  device: null
  deterministic: false

# =============================================================================
# DATA SETTINGS
# =============================================================================

data:
  data_dir: "data/icu_ecgs_24h/P1"
  sampling_rate: 500.0
  window_seconds: 10.0
  num_leads: 12
  
  los_task: "regression"
  split_strategy: "temporal_stratified"
  
  preprocessing:
    target_sampling_rate: 500.0
    window_seconds: 10.0
    filter_type: "bandpass"
    filter_lowcut: 0.5
    filter_highcut: 50.0
    filter_order: 4
    normalize: "zscore"
  
  augmentation:
    enabled: true
    gaussian_noise: true
    noise_std: 0.03
    amplitude_scaling: true
    scale_min: 0.85
    scale_max: 1.15
  
  demographic_features:
    enabled: false
  
  diagnosis_features:
    enabled: false

# =============================================================================
# MODEL ARCHITECTURE
# =============================================================================

model:
  type: "XResNet1D101"
  num_classes: 10  # LOS bin classification: [0,1), [1,2), ..., [9, +inf) = 10 classes
  
  # FastAI xResNet1D-101-specific architecture parameters
  # Architecture follows FastAI xResNet structure
  # ~3.7M parameters (pretrained on PTB-XL)
  
  # Pretrained weights configuration
  pretrained:
    enabled: true  # Load pretrained weights from PTB-XL
    weights_path: "data/pretrained_weights/PTB-Xl-analysis/fastai_xresnet1d101.pth"
    freeze_backbone: true  # Feature extraction: only train head (backbone frozen)

# =============================================================================
# TRAINING HYPERPARAMETERS
# =============================================================================

training:
  batch_size: 64
  num_epochs: 50
  num_workers: 4
  pin_memory: true
  
  optimizer:
    type: "Adam"
    lr: 5e-4
    weight_decay: 1e-4
    betas: [0.9, 0.999]
  
  gradient_clip_norm: 1.0
  dropout_rate: 0.3
  
  scheduler:
    type: "ReduceLROnPlateau"
    factor: 0.1
    patience: 5
    min_lr: 1e-6
  
  loss:
    type: "mse"

# =============================================================================
# VALIDATION & TEST SETTINGS
# =============================================================================

validation:
  val_split: 0.1
  val_frequency: 1

test_split: 0.1

# =============================================================================
# EARLY STOPPING
# =============================================================================

early_stopping:
  enabled: true
  patience: 7
  monitor: "val_loss"
  mode: "min"

# =============================================================================
# CHECKPOINTING & LOGGING
# =============================================================================

checkpoint:
  save_dir: "outputs/checkpoints"
  save_frequency: 1
  save_best: true
  metric: "val_loss"

logging:
  log_dir: "outputs/logs"
  use_tensorboard: true
  log_frequency: 10

# =============================================================================
# EVALUATION METRICS
# =============================================================================

evaluation:
  metrics:
    - "mae"
    - "rmse"
    - "r2"
    - "median_ae"
    - "accuracy"
    - "auc_roc"

# =============================================================================
# MULTI-TASK LEARNING
# =============================================================================

multi_task:
  enabled: true
  admissions_path: "data/labeling/labels_csv/admissions.csv"
  los_loss_weight: 1.0
  mortality_loss_weight: 1.0
  mortality_use_weighted_loss: false
  mortality_pos_weight: null
