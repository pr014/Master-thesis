# Baseline configuration for all_icu_ecgs dataset with class weights (SQRT method)
# This config is specifically for the all_icu_ecgs_P1 dataset
# Class weights are calculated using Square-Root Weighting (SQINV) method
# 
# IMPORTANT: This config is dataset-specific. Do not use for other datasets!
#
# Weighting Method: Square-Root Weighting (SQINV)
# Formula: w_i = sqrt(n_total) / sqrt(n_i), then normalized to mean = 1.0
# Rationale: Square-root of inverse-frequency flattens extreme weights and
#            avoids overfitting on rare classes (common in medical/CV studies)

# Random seed for reproducibility
seed: 42

# Device settings
device:
  device: null  # null = auto-select (CUDA if available, else CPU)
  deterministic: false

# Data settings for all_icu_ecgs dataset
data:
  data_dir: "data/all_icu_ecgs/P1"
  sampling_rate: 500.0  # Hz
  window_seconds: 10.0  # seconds
  num_leads: 12  # 12-lead ECG
  
  # LOS binning strategy
  los_binning:
    strategy: "intervals"  # "intervals" (old 10-class) or "exact_days" (new, e.g., 8-class)
    max_days: 9  # Only used for "exact_days" strategy (default: 9)
  
  # Preprocessing (same as baseline)
  preprocessing:
    target_sampling_rate: 500.0
    window_seconds: 10.0
    filter_type: "bandpass"
    filter_lowcut: 0.5
    filter_highcut: 50.0
    filter_order: 4
    normalize: "zscore"
  
  # Data augmentation (same as baseline)
  augmentation:
    enabled: true
    gaussian_noise: true
    noise_std: 0.03
    amplitude_scaling: true
    scale_min: 0.85
    scale_max: 1.15

# Training hyperparameters
training:
  batch_size: 64
  num_epochs: 50
  num_workers: 4
  pin_memory: true
  
  # Optimizer
  optimizer:
    type: "Adam"
    lr: 5e-4
    weight_decay: 1e-4
    betas: [0.9, 0.999]
  
  # Gradient clipping
  gradient_clip_norm: 1.0
  
  # Dropout rate
  dropout_rate: 0.3
  
  # Learning rate scheduler
  scheduler:
    type: "ReduceLROnPlateau"
    factor: 0.1
    patience: 5
    min_lr: 1e-6
  
  # Loss function with class weights for all_icu_ecgs dataset (SQRT method)
  loss:
    type: "weighted_ce"
    weight: [0.4, 0.5, 0.7, 1.0, 1.2, 1.5, 1.7, 0.9]  # TO_BE_UPDATED
  # Weights calculated based on training set distribution (34,838 samples):
  # Class distribution: [12411, 8322, 4543, 2654, 1672, 1089, 829, 3318]
  # Method: Square-Root Weighting (SQINV)
  #   Formula: w_i = sqrt(n_total) / sqrt(n_i)
  # Normalized so mean = 1.0
  # Class 0: 0.45 (12,411 samples, 35.62%)
  # Class 1: 0.54 (8,322 samples, 23.89%)
  # Class 2: 0.74 (4,543 samples, 13.04%)
  # Class 3: 0.96 (2,654 samples, 7.62%)
  # Class 4: 1.21 (1,672 samples, 4.80%)
  # Class 5: 1.51 (1,089 samples, 3.13%)
  # Class 6: 1.73 (829 samples, 2.38%)
  # Class 7: 0.86 (3,318 samples, 9.52%)
  #   Formula: w_i = sqrt(n_total) / sqrt(n_i)
  #   Formula: w_i = sqrt(n_total) / sqrt(n_i)
    # 
    # Comparison: SQRT method reduces weight range compared to balanced weighting
    # This should prevent the model from being too conservative and improve
    # learning of minority classes without extreme overfitting

# Validation settings
validation:
  val_split: 0.1  # 10% for 80-10-10 split
  val_frequency: 1

# Test settings
test_split: 0.1  # 10% for 80-10-10 split

# Early stopping
early_stopping:
  enabled: true
  patience: 7
  monitor: "val_loss"
  mode: "min"

# Checkpointing
checkpoint:
  save_dir: "outputs/checkpoints"
  save_frequency: 1
  save_best: true
  metric: "val_loss"

# Logging
logging:
  log_dir: "outputs/logs"
  use_tensorboard: true
  log_frequency: 10

# Evaluation metrics
evaluation:
  metrics:
    - "accuracy"
    - "f1_score"
    - "precision"
    - "recall"
    - "auc_roc"
    - "auc_pr"

