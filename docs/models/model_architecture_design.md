# Model Architecture Design - Methodisches Konstrukt

## Ãœbersicht

Dieses Dokument beschreibt die methodische Struktur fÃ¼r den Aufbau von Deep-Learning-Modellen fÃ¼r die ECG-Klassifikation. Die Architekturen umfassen:
1. **CNN** (Convolutional Neural Network)
2. **LSTM** (Long Short-Term Memory)
3. **Hybrid CNN-LSTM**
4. **Transformer**
5. **Foundation Model** (optional)

## Prinzipien des Designs

### 1. ModularitÃ¤t
- **Getrennte Verantwortlichkeiten**: Jede Komponente hat eine klar definierte Aufgabe
- **Wiederverwendbarkeit**: Gemeinsame Komponenten werden von allen Modellen genutzt
- **Erweiterbarkeit**: Neue Modelle kÃ¶nnen einfach hinzugefÃ¼gt werden

### 2. Shared Components (Gemeinsame Komponenten)
Viele Komponenten werden von allen Modellen geteilt:
- **Dataloader**: Einheitliches Interface fÃ¼r Dateneingabe
- **Preprocessing**: Standardisierte Signalvorverarbeitung
- **Augmentation**: Gemeinsame Augmentationsstrategien
- **Training Loop**: Gemeinsame Trainingsinfrastruktur
- **Evaluation**: Einheitliche Metriken und Logging
- **Configuration**: YAML-basierte Konfiguration

### 3. Model-Specific Components
Jedes Modell hat eigene spezifische Komponenten:
- **Model Architecture**: Modell-spezifische Architektur
- **Input Format**: Falls abweichend vom Standard
- **Loss Function**: Falls modell-spezifisch
- **Optimizer Settings**: Falls unterschiedlich

---

## Verzeichnisstruktur

```
src/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ecg_loader.py              # Basis ECG-Loader (bereits vorhanden)
â”‚   â”œâ”€â”€ ecg_dataset.py             # PyTorch Dataset-Wrapper
â”‚   â”œâ”€â”€ dataloader_factory.py      # Factory fÃ¼r DataLoader-Erstellung
â”‚   â””â”€â”€ preprocessing/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ signal_processing.py   # Filterung, Normalisierung, etc.
â”‚       â”œâ”€â”€ augmentation.py        # Data Augmentation (zeitlich, frequenz-basiert)
â”‚       â””â”€â”€ transforms.py          # PyTorch Transforms
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py              # Basisklasse fÃ¼r alle Modelle
â”‚   â”œâ”€â”€ cnn/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py               # CNN-Architektur
â”‚   â”‚   â””â”€â”€ config.yaml            # CNN-spezifische Konfiguration
â”‚   â”œâ”€â”€ lstm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py               # LSTM-Architektur
â”‚   â”‚   â””â”€â”€ config.yaml
â”‚   â”œâ”€â”€ hybrid_cnn_lstm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py               # Hybrid-Architektur
â”‚   â”‚   â””â”€â”€ config.yaml
â”‚   â”œâ”€â”€ transformer/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py               # Transformer-Architektur
â”‚   â”‚   â””â”€â”€ config.yaml
â”‚   â””â”€â”€ foundation/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ model.py               # Foundation Model (z.B. pre-trained)
â”‚       â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py                 # Basis Trainer-Klasse
â”‚   â”œâ”€â”€ train_loop.py              # Gemeinsamer Training Loop
â”‚   â”œâ”€â”€ callbacks.py               # Callbacks (EarlyStopping, Checkpointing, etc.)
â”‚   â””â”€â”€ losses.py                  # Loss-Funktionen
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py                 # Metriken (Accuracy, F1, AUC, etc.)
â”‚   â”œâ”€â”€ evaluator.py               # Evaluator-Klasse
â”‚   â””â”€â”€ visualization.py           # Visualisierungen fÃ¼r Ergebnisse
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config_loader.py           # YAML-Konfigurationslader
    â”œâ”€â”€ logger.py                  # Logging-Utility
    â””â”€â”€ device.py                  # GPU/CPU-Handling

configs/
â”œâ”€â”€ base/
â”‚   â””â”€â”€ default.yaml               # Basis-Konfiguration fÃ¼r alle Modelle
â”œâ”€â”€ visualization/
â”‚   â””â”€â”€ default_paths.yaml         # Pfade fÃ¼r Visualisierungs-Skripte
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ cnn.yaml
â”‚   â”œâ”€â”€ lstm.yaml
â”‚   â”œâ”€â”€ hybrid_cnn_lstm.yaml
â”‚   â”œâ”€â”€ transformer.yaml
â”‚   â””â”€â”€ foundation.yaml
â””â”€â”€ experiment/
    â””â”€â”€ [experiment_name].yaml     # Experiment-spezifische Konfigurationen
```

---

## Komponenten-Details

### 1. Data Layer (Gemeinsam)

#### 1.1 ECG Dataset (`src/data/ecg_dataset.py`)
**Zweck**: PyTorch Dataset-Klasse, die die vorhandene `ECGDemoDataset` erweitert

**Verantwortlichkeiten**:
- LÃ¤dt ECG-Signale aus WFDB-Dateien
- Wendet Preprocessing an
- Wendet Augmentation an (nur im Training)
- Gibt einheitliches Format zurÃ¼ck: `{"signal": Tensor, "label": Tensor, "meta": Dict}`

**Interface**:
```python
class ECGDataset(Dataset):
    def __init__(
        self,
        records: List[Dict],
        labels: Optional[Dict] = None,
        preprocess: Optional[Callable] = None,
        augmentation: Optional[Callable] = None,
        split: str = "train"  # "train", "val", "test"
    ):
        ...
    
    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:
        ...
```

#### 1.2 Preprocessing (`src/data/preprocessing/signal_processing.py`)
**Zweck**: Standardisierte Signalvorverarbeitung

**Funktionen**:
- **Normalisierung**: Z-Score Normalisierung, Min-Max Normalisierung
- **Filterung**: Bandpass-Filter, Notch-Filter (z.B. 50/60 Hz), Baseline-Wandering-Reduktion
- **Resampling**: Einheitliche Sampling-Rate (z.B. 500 Hz)
- **Windowing**: Fixe FensterlÃ¤nge (z.B. 10 Sekunden)
- **Lead Selection**: Auswahl relevanter Leads (12-Lead, einzelne Leads, etc.)

**Interface**:
```python
def preprocess_ecg(
    signal: np.ndarray,
    fs: float,
    target_fs: float = 500.0,
    normalize: str = "zscore",  # "zscore", "minmax", None
    filter_type: str = "bandpass",  # "bandpass", "notch", None
    remove_baseline: bool = True
) -> np.ndarray:
    ...
```

#### 1.3 Data Augmentation (`src/data/preprocessing/augmentation.py`)
**Zweck**: Data Augmentation fÃ¼r bessere Generalisierung

**Augmentationen**:
- **Zeitbereich**: Time Warping, Time Shift, Scaling, Gaussian Noise
- **Frequenzbereich**: Frequency Masking, Mixup
- **Lead-spezifisch**: Lead Dropout, Lead Permutation

**Interface**:
```python
class ECGAugmentation:
    def __init__(
        self,
        time_warp: bool = False,
        time_shift: bool = False,
        add_noise: bool = False,
        scale: bool = False,
        lead_dropout: bool = False,
        ...
    ):
        ...
    
    def __call__(self, signal: torch.Tensor) -> torch.Tensor:
        ...
```

#### 1.4 DataLoader Factory (`src/data/dataloader_factory.py`)
**Zweck**: Zentralisierte Erstellung von DataLoaders

**Verantwortlichkeiten**:
- Erstellt Train/Val/Test Splits
- Erstellt PyTorch DataLoaders mit korrekten Parametern
- UnterstÃ¼tzt unterschiedliche Batch-Sizes fÃ¼r verschiedene Modelle

**Interface**:
```python
def create_dataloaders(
    data_dir: Path,
    config: Dict,
    model_type: str = "cnn"
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    Returns: train_loader, val_loader, test_loader
    """
    ...
```

---

### 2. Model Layer (Model-Spezifisch)

#### 2.1 Base Model (`src/models/base_model.py`)
**Zweck**: Abstrakte Basisklasse fÃ¼r alle Modelle

**Verantwortlichkeiten**:
- Definiert gemeinsames Interface (`forward()`, `predict()`)
- Gemeinsame Hilfsmethoden (Parameter-Counting, etc.)
- Enforced durch alle Modell-Implementierungen

**Interface**:
```python
class BaseECGModel(nn.Module):
    def __init__(self, config: Dict):
        super().__init__()
        ...
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: ECG signal tensor (B, C, T) or (B, T, C)
            B: Batch size
            C: Number of channels/leads
            T: Time steps
        Returns:
            logits: (B, num_classes)
        """
        raise NotImplementedError
    
    def predict(self, x: torch.Tensor) -> torch.Tensor:
        """Returns class predictions"""
        ...
```

#### 2.2 CNN Model (`src/models/cnn/model.py`)
**Architektur-Ãœberlegungen**:
- **Input Format**: (B, C, T) - Zeitreihe als 1D/2D Convolutions
- **Layers**: Conv1D/Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ Dropout
- **Feature Extraction**: Mehrere Convolutional Blocks
- **Classification Head**: Global Average Pooling â†’ Dense Layers â†’ Output

**Typische Architektur**:
```
Input (B, 12, 5000)  # 12 leads, 10s @ 500Hz
  â†“
Conv1D Blocks (tiefe Feature-Extraktion)
  â†“
Global Average Pooling
  â†“
Dense Layers
  â†“
Output (B, num_classes)
```

#### 2.3 LSTM Model (`src/models/lstm/model.py`)
**Architektur-Ãœberlegungen**:
- **Input Format**: (B, T, C) - Sequenz-basiert
- **Layers**: LSTM/BiLSTM â†’ Dropout â†’ Dense â†’ Output
- **Varianten**: Single-Layer vs. Multi-Layer, Bidirectional

**Typische Architektur**:
```
Input (B, 5000, 12)  # Time-first fÃ¼r LSTM
  â†“
LSTM/BiLSTM Layers
  â†“
Last Hidden State oder Attention Pooling
  â†“
Dense Layers
  â†“
Output (B, num_classes)
```

#### 2.4 Hybrid CNN-LSTM (`src/models/hybrid_cnn_lstm/model.py`)
**Architektur-Ãœberlegungen**:
- **Input Format**: (B, C, T) oder (B, T, C)
- **Zwei-Stufen**: CNN fÃ¼r Feature-Extraktion â†’ LSTM fÃ¼r Sequenz-Modellierung
- **Fusion**: Verschiedene Fusion-Strategien (Concatenation, Attention)

**Typische Architektur**:
```
Input (B, 12, 5000)
  â†“
CNN Feature Extractor (B, 12, 5000) â†’ (B, features, reduced_time)
  â†“
Reshape fÃ¼r LSTM (B, reduced_time, features)
  â†“
LSTM Layers
  â†“
Fusion + Dense
  â†“
Output (B, num_classes)
```

#### 2.5 Transformer Model (`src/models/transformer/model.py`)
**Architektur-Ãœberlegungen**:
- **Input Format**: (B, T, C) oder (B, C, T) mit Patch Embedding
- **Components**: Patch Embedding â†’ Positional Encoding â†’ Transformer Blocks â†’ Classification Head
- **Variants**: Vision Transformer (ViT)-Style, Time Series Transformer

**Typische Architektur**:
```
Input (B, 12, 5000)
  â†“
Patch Embedding (B, num_patches, embed_dim)
  â†“
+ Positional Encoding
  â†“
Transformer Encoder Blocks (Multi-Head Attention + FFN)
  â†“
CLS Token oder Mean Pooling
  â†“
Classification Head
  â†“
Output (B, num_classes)
```

#### 2.6 Foundation Model (`src/models/foundation/model.py`)
**Architektur-Ãœberlegungen**:
- **Option 1**: Pre-trained Modell (z.B. aus HuggingFace, PhysioNet Challenge)
- **Option 2**: Self-Supervised Pre-training (z.B. Masked Autoencoder, Contrastive Learning)
- **Fine-tuning**: Transfer Learning auf spezifische Aufgabe

**Strategien**:
- **Feature Extractor**: Pre-trained Model als Feature-Extraktor + Task-spezifischer Head
- **Fine-tuning**: VollstÃ¤ndiges Fine-tuning aller Parameter
- **Partial Fine-tuning**: Nur bestimmte Layers fine-tunen

---

### 3. Training Layer (Gemeinsam)

#### 3.1 Trainer (`src/training/trainer.py`)
**Zweck**: Basisklasse fÃ¼r Training

**Verantwortlichkeiten**:
- Model Training
- Validation
- Checkpointing
- Logging (TensorBoard, Weights & Biases, etc.)
- Early Stopping

**Interface**:
```python
class BaseTrainer:
    def __init__(
        self,
        model: BaseECGModel,
        train_loader: DataLoader,
        val_loader: DataLoader,
        config: Dict,
        device: torch.device
    ):
        ...
    
    def train(self) -> Dict[str, List[float]]:
        """Returns training history"""
        ...
    
    def validate(self) -> Dict[str, float]:
        """Returns validation metrics"""
        ...
```

#### 3.2 Loss Functions (`src/training/losses.py`)
**Zweck**: Loss-Funktionen (gemeinsam, aber konfigurierbar pro Modell)

**MÃ¶gliche Losses**:
- Cross-Entropy Loss
- Focal Loss (fÃ¼r class imbalance)
- Weighted Cross-Entropy
- Label Smoothing

#### 3.3 Callbacks (`src/training/callbacks.py`)
**Zweck**: Callbacks fÃ¼r Training

**Callbacks**:
- EarlyStopping: Stoppt Training bei keinem Fortschritt
- ModelCheckpoint: Speichert beste Modelle
- LearningRateScheduler: Passt Learning Rate an
- TensorBoardLogger: Loggt Metriken

---

### 4. Evaluation Layer (Gemeinsam)

#### 4.1 Metrics (`src/evaluation/metrics.py`)
**Zweck**: Evaluationsmetriken

**Metriken**:
- Accuracy, Precision, Recall, F1-Score
- AUC-ROC, AUC-PR
- Confusion Matrix
- Classification Report

#### 4.2 Evaluator (`src/evaluation/evaluator.py`)
**Zweck**: Zentrale Evaluationsklasse

**Verantwortlichkeiten**:
- Evaluiert Model auf Test-Set
- Berechnet alle Metriken
- Speichert Ergebnisse

---

### 5. Configuration Layer

#### 5.1 Konfigurationsstruktur
**Hierarchie**:
```
base/default.yaml          # Basis-Konfiguration
  â”œâ”€â”€ model/cnn.yaml       # Model-spezifische Overrides
  â””â”€â”€ experiment/exp1.yaml # Experiment-spezifische Overrides
```

**Konfigurationsbereiche**:
- **Data**: Pfade, Preprocessing-Parameter, Augmentation
- **Model**: Architektur-Parameter (Layers, Hidden Units, etc.)
- **Training**: Optimizer, Learning Rate, Epochs, Batch Size
- **Evaluation**: Metriken, Thresholds
- **Logging**: Logging-Config, Checkpoint-Pfade

---

## Datenfluss

### Training Pipeline
```
1. Configuration laden (YAML)
   â†“
2. DataLoader erstellen (Factory)
   â”œâ”€â”€ Preprocessing anwenden
   â”œâ”€â”€ Augmentation (nur Training)
   â””â”€â”€ Batch-Erstellung
   â†“
3. Modell instanziieren (Model Factory)
   â†“
4. Trainer erstellen
   â”œâ”€â”€ Loss Function
   â”œâ”€â”€ Optimizer
   â”œâ”€â”€ Scheduler
   â””â”€â”€ Callbacks
   â†“
5. Training Loop
   â”œâ”€â”€ Forward Pass
   â”œâ”€â”€ Loss Berechnung
   â”œâ”€â”€ Backward Pass
   â”œâ”€â”€ Validation
   â””â”€â”€ Checkpointing
   â†“
6. Evaluation auf Test-Set
   â†“
7. Ergebnisse speichern
```

### Inference Pipeline
```
1. Model laden (Checkpoint)
   â†“
2. ECG Signal laden
   â†“
3. Preprocessing (wie im Training)
   â†“
4. Forward Pass
   â†“
5. Postprocessing (Softmax, Argmax)
   â†“
6. Ergebnis zurÃ¼ckgeben
```

---

## Gemeinsame vs. Model-Spezifische Komponenten

### âœ… Gemeinsam (Shared)
- **Dataloader**: Einheitliches Interface fÃ¼r alle Modelle
- **Preprocessing**: Standardisierte Signalvorverarbeitung
- **Augmentation**: Gemeinsame Augmentationsstrategien
- **Training Loop**: Gemeinsame Infrastruktur
- **Evaluation**: Einheitliche Metriken
- **Configuration**: YAML-basiert, hierarchisch
- **Logging**: TensorBoard, etc.
- **Device Handling**: GPU/CPU

### ðŸ”· Model-Spezifisch
- **Architektur**: Jedes Modell hat eigene Architektur
- **Input Format**: 
  - CNN: (B, C, T) - Channel-first
  - LSTM: (B, T, C) - Time-first
  - Hybrid: AbhÃ¤ngig von Fusion-Strategie
  - Transformer: (B, T, C) mit Patches
- **Hyperparameter**: Learning Rate, Batch Size kÃ¶nnen unterschiedlich sein
- **Loss Function**: Kann modell-spezifisch sein (optional)
- **Optimizer Settings**: Kann unterschiedlich sein

---

## Implementierungsreihenfolge (Empfehlung)

### Phase 1: Foundation (Shared Components)
1. âœ… ECG Dataset erweitern (PyTorch Dataset)
2. âœ… Preprocessing-Modul
3. âœ… Augmentation-Modul
4. âœ… DataLoader Factory
5. âœ… Base Model Klasse
6. âœ… Configuration System

### Phase 2: Training Infrastructure
7. âœ… Trainer-Klasse
8. âœ… Loss Functions
9. âœ… Callbacks
10. âœ… Metrics

### Phase 3: Model Implementation
11. âœ… CNN Model (am einfachsten zu starten)
12. âœ… LSTM Model
13. âœ… Hybrid CNN-LSTM
14. âœ… Transformer Model
15. âœ… Foundation Model (optional)

### Phase 4: Evaluation & Integration
16. âœ… Evaluator
17. âœ… Experiment-Scripts
18. âœ… Inference-Pipeline

---

## Best Practices

### 1. Reproduzierbarkeit
- Random Seeds setzen (PyTorch, NumPy, Python)
- Deterministic Operations (wenn mÃ¶glich)
- Configuration-Versioning

### 2. Experiment-Tracking
- Alle Konfigurationen speichern
- Logs fÃ¼r alle Experimente
- Model-Checkpoints mit Metadaten

### 3. Code-Organisation
- Klare Trennung zwischen Shared und Model-Specific Code
- Type Hints fÃ¼r bessere Dokumentation
- Docstrings fÃ¼r alle Funktionen/Klassen

### 4. Testing
- Unit Tests fÃ¼r Preprocessing
- Integration Tests fÃ¼r Training Pipeline
- Model-Spezifische Tests

---

## Offene Fragen / Design-Entscheidungen

1. **Input Format Standardisierung**:
   - Soll es einen einheitlichen Input-Format-Converter geben?
   - Oder akzeptiert jedes Modell sein bevorzugtes Format?

2. **Label Format**:
   - Single-Label oder Multi-Label Klassifikation?
   - Regression-Tasks?

3. **Multi-Task Learning**:
   - Sollen Modelle mehrere Tasks gleichzeitig lernen kÃ¶nnen?

4. **Ensemble Methods**:
   - Sollen Ensembles unterstÃ¼tzt werden?

5. **Model Zoo**:
   - Sollen pre-trained Modelle gespeichert/geteilt werden?

---

## NÃ¤chste Schritte

Nach Genehmigung dieses Designs:
1. Detaillierte Spezifikationen fÃ¼r jede Komponente
2. API-Design fÃ¼r Interfaces
3. Konfigurationsschemas definieren
4. Implementierung starten (Phase 1)

